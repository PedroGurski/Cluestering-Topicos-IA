# -*- coding: utf-8 -*-
"""Clustering_visualiza√ß√£o.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rg6qPFpwyH_LNrsP3mjuy9lLcE7u5Klu
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_moons, make_blobs, make_circles
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

# EDA cluster_moons

# Carregar dados
X, y = make_moons(n_samples=3000, noise=0.2, random_state=42)
df = pd.DataFrame(X, columns=['x1', 'x2'])
df['target'] = y

# Estat√≠sticas descritivas
print(df.describe())
print()

# Visualiza√ß√µes iniciais
plt.figure(figsize=(5,5))
sns.scatterplot(data=df, x='x1', y='x2', hue='target', palette='viridis')
plt.title("Distribui√ß√£o do dataset make_moons")
plt.axis('equal')
plt.show()

# BoxPlot
sns.boxplot(data=df[['x1', 'x2']])
plt.title("Boxplots de x1 e x2")
plt.show()
print()

# Histograma
sns.histplot(data=df, x='x1', hue='target', kde=True, element="step")
sns.histplot(data=df, x='x2', hue='target', kde=True, element="step")
plt.title("Histogramas por classe")
plt.show()
print()

# Pr√©-processamento
scaler = StandardScaler()
df[['x1_scaled', 'x2_scaled']] = scaler.fit_transform(df[['x1', 'x2']])

# Treinamento simples e avalia√ß√£o
XMoons_scaled = df[['x1_scaled', 'x2_scaled']]
yMoons = df['target'].values
X_train, X_test, y_train, y_test = train_test_split(XMoons_scaled, yMoons, test_size=0.3, random_state=42)

# Teste Regress√£o Log√≠stica
model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# Matriz Confus√£o
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap="Blues")
plt.title("Matriz de Confus√£o")
plt.show()

# EDA cluster_blobs

# Carregar dados
X, y = make_blobs(n_samples=3000, centers=3, cluster_std=1.2, random_state=42)
df = pd.DataFrame(X, columns=['x1', 'x2'])
df['target'] = y

# Estat√≠sticas descritivas
print(df.describe())
print()

# Visualiza√ß√µes iniciais
plt.figure(figsize=(5,5))
sns.scatterplot(data=df, x='x1', y='x2', hue='target', palette='viridis')
plt.title("Distribui√ß√£o do dataset make_blobs")
plt.axis('equal')
plt.show()

# BoxPlot
sns.boxplot(data=df[['x1', 'x2']])
plt.title("Boxplots de x1 e x2")
plt.show()
print()

# Histograma
sns.histplot(data=df, x='x1', hue='target', kde=True, element="step")
sns.histplot(data=df, x='x2', hue='target', kde=True, element="step")
plt.title("Histogramas por classe")
plt.show()
print()

# Pr√©-processamento
scaler = StandardScaler()
df[['x1_scaled', 'x2_scaled']] = scaler.fit_transform(df[['x1', 'x2']])

# Treinamento simples e avalia√ß√£o
XBlobs_scaled = df[['x1_scaled', 'x2_scaled']]
yBlobs = df['target'].values
X_train, X_test, y_train, y_test = train_test_split(XBlobs_scaled, yBlobs, test_size=0.3, random_state=42)

# Teste Regress√£o Log√≠stica
model = LogisticRegression(multi_class="multinomial", solver="lbfgs")
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# Matriz Confus√£o
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap="Blues")
plt.title("Matriz de Confus√£o")
plt.show()

# EDA cluster_circles

# Carregar dados
X, y = make_circles(n_samples=3000, noise=0.1, factor=0.5, random_state=42)
df = pd.DataFrame(X, columns=['x1', 'x2'])
df['target'] = y

# Estat√≠sticas descritivas
print(df.describe())
print()

# Visualiza√ß√µes iniciais
plt.figure(figsize=(5,5))
sns.scatterplot(data=df, x='x1', y='x2', hue='target', palette='viridis')
plt.title("Distribui√ß√£o do dataset make_circles")
plt.axis('equal')
plt.show()

# BoxPlot
sns.boxplot(data=df[['x1', 'x2']])
plt.title("Boxplots de x1 e x2")
plt.show()
print()

# Histograma
sns.histplot(data=df, x='x1', hue='target', kde=True, element="step")
sns.histplot(data=df, x='x2', hue='target', kde=True, element="step")
plt.title("Histogramas por classe")
plt.show()
print()

# Pr√©-processamento
scaler = StandardScaler()
df[['x1_scaled', 'x2_scaled']] = scaler.fit_transform(df[['x1', 'x2']])

# Treinamento simples e avalia√ß√£o
XCircles_scaled = df[['x1_scaled', 'x2_scaled']]
yCircles = df['target'].values
X_train, X_test, y_train, y_test = train_test_split(XCircles_scaled, yCircles, test_size=0.3, random_state=42)

# Teste Regress√£o Log√≠stica
model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# Matriz Confus√£o
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
disp.plot(cmap="Blues")
plt.title("Matriz de Confus√£o")
plt.show()

"""**======================================================================================================
ETAPA 3: Resultados preliminares
======================================================================================================**
"""

from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.metrics import adjusted_rand_score, silhouette_score, normalized_mutual_info_score, v_measure_score

def aplicar_clusterizacao(X, y_true, nome_dataset):
    """
    Aplica K-Means, DBSCAN e Clusteriza√ß√£o Hier√°rquica e compara resultados.
    """
    print(f"\n{'='*60}")
    print(f"üìä RESULTADOS DE CLUSTERIZA√á√ÉO PARA: {nome_dataset.upper()}")
    print(f"{'='*60}\n")

    modelos = {
        'K-Means': KMeans(n_clusters=len(np.unique(y_true)), random_state=42),
        'DBSCAN': DBSCAN(eps=0.15, min_samples=10),
        'Hier√°rquico': AgglomerativeClustering(n_clusters=len(np.unique(y_true)))
    }

    for nome, modelo in modelos.items():
        clusters = modelo.fit_predict(X)

        # Avalia√ß√µes
        ari = adjusted_rand_score(y_true, clusters)
        sil = silhouette_score(X, clusters) if len(set(clusters)) > 1 else np.nan
        nmi = normalized_mutual_info_score(y_true, clusters)
        vmeasure = v_measure_score(y_true, clusters)

        print(f"{nome}:")
        print(f" - Adjusted Rand Index (ARI): {ari:.4f}")
        print(f" - Silhouette Score: {sil:.4f}")
        print(f" - NMI: {nmi:.4f}")
        print(f" - V-measure: {vmeasure:.4f}\n")

        # Visualiza√ß√£o
        plt.figure(figsize=(5,5))
        sns.scatterplot(x=X[:,0], y=X[:,1], hue=clusters, palette='tab10')
        plt.title(f"{nome_dataset} - {nome}")
        plt.show()

aplicar_clusterizacao(XMoons_scaled.values, yMoons, "make_moons")

aplicar_clusterizacao(XBlobs_scaled.values, yBlobs, "make_blobs")

aplicar_clusterizacao(XCircles_scaled.values, yCircles, "make_circles")

import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import make_blobs
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import AgglomerativeClustering

from scipy.cluster.hierarchy import linkage, dendrogram, fcluster


# Par√¢metros do exemplo
N_SAMPLES   = 30
CENTERS     = 3
STD         = 0.70
SEED        = 42
K_CLUSTERS  = 3          # Clusters
LINKAGE     = "ward"
METRIC      = "euclidean"
LIFT_FACTOR = 0.12

# Tamanho das figuras
FIG_W = 8
FIG_H = 5
plt.rcParams["figure.dpi"] = 140
plt.rcParams["savefig.bbox"] = "tight"


X, _ = make_blobs(
    n_samples=N_SAMPLES, centers=CENTERS,
    cluster_std=STD, random_state=SEED
)
X = StandardScaler().fit_transform(X)
Z = linkage(X, method=LINKAGE, metric=METRIC)

# Altura de refer√™ncia do corte para obter K_CLUSTERS
if K_CLUSTERS > 1:
    cut_height = Z[-(K_CLUSTERS - 1), 2]
else:
    cut_height = Z[-1, 2] + 1.0

# R√≥tulos a partir do corte em k clusters (equivalente ao Agglomerative com n_clusters=k)
labels = fcluster(Z, t=K_CLUSTERS, criterion="maxclust")


plt.figure(figsize=(FIG_W, FIG_H))
ddata = dendrogram(
    Z,
    labels=np.arange(len(X)),
    leaf_rotation=0,
    leaf_font_size=11,
    color_threshold=cut_height,
    above_threshold_color="gray",
)

# Cria ‚Äúrespiro‚Äù sob as folhas para melhor visualiza√ß√£o
max_h = np.max([max(dc) for dc in ddata["dcoord"]]) if ddata["dcoord"] else Z[-1, 2]
offset = LIFT_FACTOR * max_h
ymin, ymax = plt.ylim()
plt.ylim(bottom=ymin - offset, top=ymax)
plt.title(f"Dendrograma (linkage = {LINKAGE})")
plt.ylabel(f"dist√¢ncia ({METRIC})")
plt.grid(axis="y", linestyle="--", alpha=0.25)
plt.tight_layout()
plt.show()

# Mesma altura do dendrograma
plt.figure(figsize=(FIG_W, FIG_H))
for c in np.unique(labels):
    idx = labels == c
    plt.scatter(X[idx, 0], X[idx, 1], s=70, label=f"cluster {c}")

# R√≥tulo num√©rico de cada ponto para relacionar com as folhas do dendrograma
for i, (x, y) in enumerate(X):
    plt.text(x, y, f"{i}", fontsize=9, ha="center", va="center")

plt.title(f"Scatter (k={K_CLUSTERS} clusters via corte no dendrograma)")
plt.xlabel("x1 (padronizado)")
plt.ylabel("x2 (padronizado)")
plt.legend()
plt.tight_layout()
plt.show()

model = AgglomerativeClustering(n_clusters=K_CLUSTERS, linkage=LINKAGE)
labels_sklearn = model.fit_predict(X)
print("R√≥tulos via fcluster     :", labels)
print("R√≥tulos via sklearn      :", labels_sklearn)

# Agglomerative (Hier√°rquico) ‚Äî Visual somente com scatters
# Datasets: make_moons, make_blobs, make_circles
# Linkages: ward, average, complete, single

import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import make_moons, make_blobs, make_circles
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import adjusted_rand_score, silhouette_score

# Ajustes visuais globais
plt.rcParams["figure.dpi"] = 140
plt.rcParams["savefig.bbox"] = "tight"

# Utilit√°rios
def safe_silhouette(X, labels):
    uniq, counts = np.unique(labels, return_counts=True)
    if len(uniq) < 2 or np.any(counts < 2):
        return np.nan
    try:
        return silhouette_score(X, labels)
    except Exception:
        return np.nan

def make_dataset(name, random_state=42):
    if name == "make_moons":
        X, y = make_moons(n_samples=3000, noise=0.15, random_state=random_state)
    elif name == "make_blobs":
        X, y = make_blobs(n_samples=3000, centers=3, cluster_std=1.0, random_state=random_state)
    elif name == "make_circles":
        X, y = make_circles(n_samples=3000, noise=0.06, factor=0.5, random_state=random_state)
    else:
        raise ValueError("name inv√°lido")
    X = StandardScaler().fit_transform(X)
    return X, y

def run_agglomerative(X, k, linkage):
    if linkage == "ward":
        model = AgglomerativeClustering(n_clusters=k, linkage="ward")
    else:
        try:
            model = AgglomerativeClustering(n_clusters=k, linkage=linkage, metric="euclidean")
        except TypeError:
            model = AgglomerativeClustering(n_clusters=k, linkage=linkage, affinity="euclidean")
    labels = model.fit_predict(X)
    return labels

def plot_scatter_grid_for_dataset(ds_name, X, y, k, linkages=("ward","average","complete","single")):
    """
    Cria uma figura com 4 scatters (um por linkage) e uma figura com barras (ARI e Silhouette).
    """
    ncols = len(linkages)
    nrows, ncols = 2, 2
    fig, axes = plt.subplots(nrows, ncols, figsize=(7, 7), sharex=True, sharey=True)
    axes = axes.flatten()  # facilita iterar sobre axes[i]

    if ncols == 1:
        axes = [axes]

    ari_vals = []
    sil_vals = []

    # calcular limites globais antes do loop
    x_min, x_max = X[:,0].min() - 0.3, X[:,0].max() + 0.3
    y_min, y_max = X[:,1].min() - 0.3, X[:,1].max() + 0.3

    for i, lk in enumerate(linkages):
        labels = run_agglomerative(X, k, lk)
        # m√©tricas
        ari = adjusted_rand_score(y, labels)
        sil = safe_silhouette(X, labels)
        ari_vals.append(ari)
        sil_vals.append(sil)

        ax = axes[i]
        uniq = np.unique(labels)
        for c in uniq:
            idx = labels == c
            ax.scatter(X[idx, 0], X[idx, 1], s=10, label=f"c{c}")
        ax.set_title(f"{ds_name}\nlinkage={lk}\nARI={ari:.3f} | Sil={sil:.3f}")
        ax.set_xlabel("x1 (scaled)")
        if i == 0:
            ax.set_ylabel("x2 (scaled)")
        ax.set_xlim(x_min, x_max)
        ax.set_ylim(y_min, y_max)
        ax.set_aspect("equal")  # for√ßa quadrado
        ax.grid(alpha=0.25, linestyle="--")


    # legenda compacta
    handles, labels_leg = axes[-1].get_legend_handles_labels()
    if handles:
        fig.legend(handles, labels_leg, loc="lower center", ncol=min(6, len(handles)))
    fig.suptitle(f"{ds_name} ‚Äî Agglomerative (k={k})", y=1.02, fontsize=11)
    plt.tight_layout()
    plt.show()

    x = np.arange(len(linkages))
    width = 0.38

    fig2, ax2 = plt.subplots(figsize=(5, 5))
    ax2.bar(x - width/2, ari_vals, width, label="ARI")
    ax2.bar(x + width/2, sil_vals, width, label="Silhouette")
    ax2.set_xticks(x, linkages)
    ax2.set_ylim(0, 1.05)
    ax2.set_title(f"{ds_name} ‚Äî m√©tricas por linkage (k={k})")
    ax2.set_ylabel("score")
    ax2.grid(axis="y", alpha=0.25, linestyle="--")
    ax2.legend()
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":

    k_map = {
        "make_moons": 2,
        "make_blobs": 3,
        "make_circles": 2
    }
    linkages = ("ward","average","complete","single")

    for ds_name in ["make_moons", "make_blobs", "make_circles"]:
        X, y = make_dataset(ds_name, random_state=42)
        # Ward √© √≥timo em blobs; para moons/circles, average/complete tendem a respeitar melhor a forma
        plot_scatter_grid_for_dataset(ds_name, X, y, k=k_map[ds_name], linkages=linkages)